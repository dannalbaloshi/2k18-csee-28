# 2k18-csee-28 Danish Jalbani

Introduction and Motivation: 
Knowledge transfer is the main goal in modern code review, as each study survey and interview respondents have shown. Although there is a clear expectation about the Knowledge Transfer code review approach, there are no analytical studies using data dug from software repositories to assess the effectiveness of code review among "trained" developers and improve their skills. We present a mining-based study that explores how and where a code review approach helps developers improve their contribution to open source projects over time. In this paper, we will demonstrate Topias - a tool for visualizing changes in methods related to variant system data. It is implemented as a plugin for Git VCS which supports Java programming language and Intelligent IDEA. These limitations come from the refactoring minor tool we use to detect applied reflection. If you have other languages ​​or tools similar to VC, you can easily extend the plugin to support other IDEs built into the Intelligence platform.

Study Design: Hypothesis software development is a knowledge-intensive activity. Qualitative research has provided evidence that code review plays an important role in the transfer of knowledge between developers. However, there is no quantitative evidence to support this claim. During this study, we will quantitatively assess the transfer of knowledge due to code review to the software repository.

Study Context: The study context consisted of 728 developers and 4,981 software repositories. He cooperated and 77,456 rejected PR.

Developer Selection: To implement our study, we collected information about GitHub users. Who created your account in 2015? This was done to collect at least four years of collaborative history for each developer. Since the data was collected in September 2019, we can see 4 years of collaboration between users who created their GitHub account in December 2015. A four-year window is sufficient to observe the substantial PR submitted by the developers. Outcome, study. Knowledge transfer over time. Request for archiving and filtering: 818 Theme Developers have collected all the "closed" PRs that we submitted when we collected the data from the day they joined GitHub until the end of September 2019. It expanded a total of 77,456 PRs to 9,845 repositories. For each PR, we have collected the following information: (1) Date of creation: Date of submission of PR. (2) Acceptance: Whether the closed PR is accepted. (3) Closing date: The closing date of the PR. (4) ASCII text file comments: Comments left by reviewers that are clearly linked to parts of the code submitted by reviewers. Comments left by the PR author are excluded. (5) General Comments: All comments left in the PR discussion by all developers other than the PR code, except the source code comments. These comments are generally not used to invite clarity or to clarify whether PR is accepted / rejected. The source code comment, in turn, reports a clear action point for the PR author to improve the submitted code. We distinguish between source code comments and general comments, as these two categories may have different levels of technical detail. (6) Author: PR Author. (7) Contributors: All developers involved in the discussion and management of PR.

Measures:
To verify our hypothesis, we use proxies to measure the knowledge transfer experienced by developers through their past reviewed PRs and to assess the quality of developers’ contribution over time. 
Knowledge measures. We use the number of reviewed PRs developer contributed (authored) in the past (i.e., before the current PR) as a proxy of the amount of knowledge transferred to her thanks to the code review process. That is, we assume that the more closed and peer-reviewed PRs a developer has, the more knowledge the developer gained. In our study, we consider that peer-reviewed PRs are those which received at least one comment by non-bot users. The rationale behind this choice is that if no comments are given by other developers, we assume that the PR was not subject of a formal review process and, thus, it is not interesting for our goals, since no transfer knowledge can happen in that PR.


Data Analysis:
         Contribution quality measures. We assume that with the knowledge transfer one of the major benefits developers receive is the improvement of the quality of their contributions (i.e., PRs) over time. While there are a few existing metrics to evaluate code quality some limitations
Hinder their applications in our study context: 1) the software repositories involved can be written in different programming languages, making it impossible to set universal thresholds for CK metrics, let alone not all programming languages are object-oriented. 2) Metrics like bug count rely on the assumption that bugs can be identified thanks to the consistent usage of issue tracking systems, which is not always the case. General comments received. The number of general comments received
From all the developers other than the PR author. We expect
That with the increase of past reviewed PRs (i.e., with more knowledge
Transfer the developer benefited of), fewer discussions will be
Triggered by the PR, leading to a reduction of general comments.
Source code comments received. The number of source code comments received from all the developers other than the PR author. Similarly to general comments received, we would expect that the source code comments received will decrease over time as well. Acceptance Rate. The rate of the past PRs acceptance. We expect that the percentage of accepted PRs over time will increase. Accepted PR closing time. The time (expressed in minutes) between the creation and the closing of the accepted PRs. We expect that the time needed to accept PRs will decrease over time. Sentiment of source code comments. The sentiment polarity of all source code comments in the PRs. We expect that with the increase of contribution quality more appreciation will be received in the code review. Thus, the sentiment of the developer embedded in the comments should be increasingly positive over time. Sentiment of general comments. The sentiment polarity of all the general comments in the PRs. Similarly to source code comments, we expect general comments will also be more positive over time. Sentiment analysis. To calculate the sentiment polarity of the comments in the PRs, we adopted SentiStrength-SE.

Data Analysis:
               Our hypothesis suggests that developers, who benefited of higher knowledge transfer thanks to the past reviewed PRs they submitted, are also the ones contributing higher quality PRs in the project. We verify this hypothesis thanks to the data previously extracted. Each peer-reviewed PRi submitted by any of the studied developers represents a row in our dataset, reporting (i) the knowledge transfer measures, meaning the number of past reviewed PRs performed by the developer before PRi as well as our control variable, represented
By the number of commits she performed in the past.

RESULTS:
The box plots in Figures 1, 2, 3, and 4 show the trends of the dependent variables (i.e., the contribution quality measures), for both the cross- (left) and single- (right) project scenarios, with respect to the two independent variables (i.e., the knowledge measures).In particular, the top part of each figure reports the results obtained when splitting developers into “knowledge groups “based on the past reviewed PRs they submitted, while the bottom part shows the same results when grouping developers based on the number of past commits they performed. The red dot represents the mean value in each box plot.
PRs Acceptance Rate:
By looking at the boxplots reported in Fig. 1 (a) and (b), we can observe an almost flat trend of the Acceptance Rate (expressed in percentage) of PRs when the past reviewed PRs submitted by developer serve as a proxy for her knowledge. That is, at least by looking at Fig. 1 (top part), we did not observe any effect of the knowledge transfer on the likelihood of future PRs to be accepted.
Accepted PRs Closing Time:
As for the accepted PR closing time, the top part of Fig. 2 is also quite flat, for both cross- and single-project scenarios. This finding is also supported by the results of the statistical analysis, reporting negligible effect sizes for all performed comparisons.
Comments Posted in PRs:
We discuss together our findings for both the number of general comments (Fig. 3) and source code comments (Fig. 4) posted in the PRs submitted by different groups of developers. We first focus on
The top part of both figures (i.e., results related to the past reviewed PRs).
Answering our Research Question:
Our study led to what we can define a negative result. For most of the analyzed dependent variables we did not find any strong impact of the knowledge transfer in the code review process on
The quality of the contributions submitted by developers in open source projects. In particular, for the PRs acceptance rate, we did not observe any positive effect in the cross-project scenario when using past PRs as a proxy for knowledge transfer. Instead, an increase of experience over time might be more important for the improvement of the PRs acceptance rate, as demonstrated by the results achieved when using past commits as independent variable.

CONCLUSIONS
           We presented a quantitative study to investigate knowledge transferrin code review. Our results were mostly negative: we were not able to capture the positive role played by code review in knowledge
Transfer among developers, as was previously suggested in the literature [2].This came to us as a surprise, as we were confident those at least significant traces of the knowledge transfer, because despite not supporting the findings of Bachelor and Bird [2] given our results, we actually are convinced that their claims are correct. This raises a number of questions that we have addressed impart throughout the latter part of the paper, where we conjecture possible fallacies in our experiment design and notable threats to
Validity that are difficult to fully address, especially those regarding the measures we used to quantify the impact of knowledge transfer. A
