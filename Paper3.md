# 2k18-csee-28 Danish Jalbani

Introduction and Motivation: 
Knowledge transfer is the main goal in modern code review, as each study survey and interview respondents have shown. Although there is a clear expectation about the Knowledge Transfer code review approach, there are no analytical studies using data dug from software repositories to assess the effectiveness of code review among "trained" developers and improve their skills. We present a mining-based study that explores how and where a code review approach helps developers improve their contribution to open source projects over time. In this paper, we will demonstrate Topias - a tool for visualizing changes in methods related to variant system data. It is implemented as a plugin for Git VCS which supports Java programming language and Intelligent IDEA. These limitations come from the refactoring minor tool we use to detect applied reflection. If you have other languages ​​or tools similar to VC, you can easily extend the plugin to support other IDEs built into the Intelligence platform.

Study Design: Hypothesis software development is a knowledge-intensive activity. Qualitative research has provided evidence that code review plays an important role in the transfer of knowledge between developers. However, there is no quantitative evidence to support this claim. During this study, we will quantitatively assess the transfer of knowledge due to code review to the software repository.

Study Context: The study context consisted of 728 developers and 4,981 software repositories. He cooperated and 77,456 rejected PR.

Developer Selection: To implement our study, we collected information about GitHub users. Who created your account in 2015? This was done to collect at least four years of collaborative history for each developer. Since the data was collected in September 2019, we can see 4 years of collaboration between users who created their GitHub account in December 2015. A four-year window is sufficient to observe the substantial PR submitted by the developers. Outcome, study. Knowledge transfer over time. Request for archiving and filtering: 818 Theme Developers have collected all the "closed" PRs that we submitted when we collected the data from the day they joined GitHub until the end of September 2019. It expanded a total of 77,456 PRs to 9,845 repositories. For each PR, we have collected the following information: (1) Date of creation: Date of submission of PR. (2) Acceptance: Whether the closed PR is accepted. (3) Closing date: The closing date of the PR. (4) ASCII text file comments: Comments left by reviewers that are clearly linked to parts of the code submitted by reviewers. Comments left by the PR author are excluded. (5) General Comments: All comments left in the PR discussion by all developers other than the PR code, except the source code comments. These comments are generally not used to invite clarity or to clarify whether PR is accepted / rejected. The source code comment, in turn, reports a clear action point for the PR author to improve the submitted code. We distinguish between source code comments and general comments, as these two categories may have different levels of technical detail. (6) Author: PR Author. (7) Contributors: All developers involved in the discussion and management of PR.

Measurements: We use proxies to verify our hypothesis, to measure the transfer of knowledge experienced by developers through our previous reviewed PRs, and to assess the quality of developers' works over time. Dimensions of knowledge. We use the PRS developer number (author) we previously reviewed as a duplicate amount of knowledge transferred in the past (before the current PR) thanks to the code review process. That is, the more closed and peer-reviewed the developer is, the more knowledge the developer gains. In our study, we believe that peer-reviewed PRs received at least one comment from non-bot users. The reason behind this election is that if other developers do not comment, we believe that PR is not a formal review process and therefore it is not interesting for our goals, because there is no transfer of knowledge in PR. .

Data analysis: collaboration quality measures. We believe that one of the main benefits that developers gain with knowledge transfer is the improvement in the quality (i.e. PR) of their collaboration over time. Although there are some existing criteria for assessing code quality, some limitations in the context of our study may hinder their applications: 1) the software repositories contained therein may be written in different programming languages, allowing universal limitations for CK metrics which are impossible to set, programming languages ​​object-based. 2) Measurements such as bug count are based on the ability to detect errors for frequent use of problem tracking systems, which is not always the case. General comments received. Many general comments came from all developers except the PR author. With the increase in PR previously reviewed (i.e., benefiting the more knowledgeable developer), we hope that PR will initiate less discussion, which will lead to a decrease in general comments. Source code comments received. Number of source code comments from all developers other than the PR author. Similarly from the general comments received, we hope that the received source code comments will decrease over time. Acceptance rate. Previous PRS acceptance rate. We expect the accepted PR percentage to increase over time. Accepted PR full time. Time between creation and completion of approved PR (expressed in minutes). We hope that the time required to accept PR will decrease over time. Source Code Comments Punishment. Sense polarity of all source code comments in PR. We hope the code review will receive more praise with increased collaborative quality. Therefore, the feelings of the developer embedded in the comments should change positively over time. Punishment of general remarks. Polarity of all general observations in PRS. As with source code comments, we hope that general comments will become more positive over time. Sentiment analysis. To calculate the polarity of the sense of quotations in PRS, we adopted Centistrans-SE.

Data Analysis: Our hypothesis suggests that even developers who have achieved high knowledge transfer for previously reviewed PRs are providing high quality PRS for this project. Thanks to the data collected we will first validate this hypothesis. Each peer-reviewed PRI submitted by one of the studied developers represents a line in our dataset that reports the actions of the knowledge transfer, i.e. the number of PRs previously reviewed from the PRIs is represented by our control variable and previously represented. The number of commitments he has made in the past.

RESULTS:
The box plots in Figures 1, 2, 3, and 4 show the trends of the dependent variables (i.e., the contribution quality measures), for both the cross- (left) and single- (right) project scenarios, with respect to the two independent variables (i.e., the knowledge measures).In particular, the top part of each figure reports the results obtained when splitting developers into “knowledge groups “based on the past reviewed PRs they submitted, while the bottom part shows the same results when grouping developers based on the number of past commits they performed. The red dot represents the mean value in each box plot.
PRs Acceptance Rate:
By looking at the boxplots reported in Fig. 1 (a) and (b), we can observe an almost flat trend of the Acceptance Rate (expressed in percentage) of PRs when the past reviewed PRs submitted by developer serve as a proxy for her knowledge. That is, at least by looking at Fig. 1 (top part), we did not observe any effect of the knowledge transfer on the likelihood of future PRs to be accepted.
Accepted PRs Closing Time:
As for the accepted PR closing time, the top part of Fig. 2 is also quite flat, for both cross- and single-project scenarios. This finding is also supported by the results of the statistical analysis, reporting negligible effect sizes for all performed comparisons.
Comments Posted in PRs:
We discuss together our findings for both the number of general comments (Fig. 3) and source code comments (Fig. 4) posted in the PRs submitted by different groups of developers. We first focus on
The top part of both figures (i.e., results related to the past reviewed PRs).
Answering our Research Question:
Our study led to what we can define a negative result. For most of the analyzed dependent variables we did not find any strong impact of the knowledge transfer in the code review process on
The quality of the contributions submitted by developers in open source projects. In particular, for the PRs acceptance rate, we did not observe any positive effect in the cross-project scenario when using past PRs as a proxy for knowledge transfer. Instead, an increase of experience over time might be more important for the improvement of the PRs acceptance rate, as demonstrated by the results achieved when using past commits as independent variable.

CONCLUSIONS
           We presented a quantitative study to investigate knowledge transferrin code review. Our results were mostly negative: we were not able to capture the positive role played by code review in knowledge
Transfer among developers, as was previously suggested in the literature [2].This came to us as a surprise, as we were confident those at least significant traces of the knowledge transfer, because despite not supporting the findings of Bachelor and Bird [2] given our results, we actually are convinced that their claims are correct. This raises a number of questions that we have addressed impart throughout the latter part of the paper, where we conjecture possible fallacies in our experiment design and notable threats to
Validity that are difficult to fully address, especially those regarding the measures we used to quantify the impact of knowledge transfer. A
